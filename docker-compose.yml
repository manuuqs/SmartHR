version: "3.9"

services:
  # --- Base de datos: PostgreSQL con PGVector ---
  db:
    image: ankane/pgvector:latest
    container_name: smarthr_db
    environment:
      POSTGRES_DB: tfg_db
      POSTGRES_USER: tfg_user
      POSTGRES_PASSWORD: tfg_pass
    ports:
      - "5432:5432"
    volumes:
      - db_data:/var/lib/postgresql/data
    networks:
      - smarthr_net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U tfg_user -d tfg_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  # --- PGAdmin ---
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: smarthr_pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@smarthr.dev
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "5050:80"
    depends_on:
      db:
        condition: service_healthy
    networks:
      - smarthr_net
    volumes:
      - pgadmin_data:/var/lib/pgadmin

  # --- Backend Spring Boot ---
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: smarthr_backend
    depends_on:
      db:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      JWT_SECRET: smarthr-super-long-secret-key-32-bytes-min
    networks:
      - smarthr_net

  # --- Ollama LLM ---
  ollama:
    image: ollama/ollama:latest
    container_name: smarthr_ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - smarthr_net
    healthcheck:  # ← AÑADE ESTO
      test: ["CMD-SHELL", "ollama list || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s



  # --- Assistant Spring AI + Ollama ---
  assistant:
    build:
      context: ./assistant
      dockerfile: Dockerfile
    container_name: smarthr_assistant
    environment:
      JWT_SECRET: smarthr-super-long-secret-key-32-bytes-min
      SPRING_DATASOURCE_URL: jdbc:postgresql://db:5432/tfg_db
      SPRING_DATASOURCE_USERNAME: tfg_user
      SPRING_DATASOURCE_PASSWORD: tfg_pass
      SPRING_PROFILES_ACTIVE: dev

      SPRING_AI_OLLAMA_BASE_URL: http://ollama:11434
      SPRING_AI_OLLAMA_CHAT_OPTIONS_MODEL: llama3.2:3b
      SPRING_AI_OLLAMA_EMBEDDING_OPTIONS_MODEL: mxbai-embed-large
    depends_on:
      db:
        condition: service_healthy
      ollama:
        condition: service_started
    ports:
      - "9090:9090"
    networks:
      - smarthr_net

  # --- Frontend (React + Vite) ---
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        VITE_API_BASE_URL: http://localhost:8080
        VITE_ASSISTANT_BASE_URL: http://localhost:9090
    ports:
      - "3000:3000"
    depends_on:
      backend:
        condition: service_started
      assistant:
        condition: service_started
    networks:
      - smarthr_net

networks:
  smarthr_net:
    driver: bridge

volumes:
  db_data:
  pgadmin_data:
  ollama_data:
